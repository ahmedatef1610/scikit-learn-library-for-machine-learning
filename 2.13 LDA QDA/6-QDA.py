#Import Libraries
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA

from sklearn.datasets import make_blobs, make_classification , load_iris
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
# ----------------------------------------------------
# Quadratic Discriminant Analysis
# A classifier with a quadratic decision boundary, 
# generated by fitting class conditional densities to the data and using Bayesâ€™ rule.
# The model fits a Gaussian density to each class.

'''
class sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0, store_covariance=False, tol=0.0001)    
===
    - priors ndarray of shape (n_classes,), default=None
        Class priors. By default, the class proportions are inferred from the training data.
    - reg_param float, default=0.0
        Regularizes the per-class covariance estimates 
        by transforming S2 as S2 = (1 - reg_param) * S2 + reg_param * np.eye(n_features), 
        where S2 corresponds to the scaling_ attribute of a given class.
    - store_covariance bool, default=False
        If True, the class covariance matrices are explicitely computed and stored in the self.covariance_ attribute.
    - tol float, default=1.0e-4
        Absolute threshold for a singular value to be considered significant, 
        used to estimate the rank of Xk where Xk is the centered matrix of samples in class k. 
        This parameter does not affect the predictions. 
        It only controls a warning that is raised when features are considered to be colinear.
===


'''
# ----------------------------------------------------
print("="*25)

IrisData = load_iris()
X = IrisData.data
y = IrisData.target
y_hue = pd.Series(y)
y_hue[y == 0] = IrisData.target_names[0]
y_hue[y == 1] = IrisData.target_names[1]
y_hue[y == 2] = IrisData.target_names[2]
print(X.shape, IrisData.feature_names)
print(y.shape, IrisData.target_names)
# print(y)
# print(y_hue.values)
print("="*10)
# ---------
scaler = MinMaxScaler(copy=True, feature_range=(0, 1))
X = scaler.fit_transform(X)
# ---------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=16, shuffle=True)
print(X_train.shape,X_test.shape)
print(y_train.shape,y_test.shape)
print("="*25)
# ----------------------------------------------------
# Applying QDAModel Model
QDAModel = QDA()
QDAModel.fit(X_train,y_train)
print("="*10)
# ----------------------------------------------------
# Calculating Details
print('QDAModel Train Score is : ', QDAModel.score(X_train,y_train))
print('QDAModel Test Score is : ', QDAModel.score(X_test,y_test))
print("="*10)
# LDAModel Train Score is :  0.98
# LDAModel Test Score is :  0.98
# QDAModel Train Score is :  0.97
# QDAModel Test Score is :  0.96
# ----------------------------------
print('Scaling of the features in the space spanned by the class centroids : \n', QDAModel.scalings_)
# print('QDAModel singular value is : ', QDAModel.covariance_) # only exists when store_covariance is True.
print('Overall mean : \n', QDAModel.rotations_)
print('QDAModel Class-wise means is : \n', QDAModel.means_)
print(' Class priors (sum to 1) : ', QDAModel.priors_)
print('Unique class labels : ', QDAModel.classes_)
print("="*25)
# ----------------------------------------------------
y_pred = QDAModel.predict(X_test)
# y_pred_prob = QDAModel.predict_proba(X_test)
# print('Pred Probabilities Value for QDAModel is : ', y_pred_prob[:5])
print('Pred Value for QDAModel is : ', y_pred[:5])
print('True Value for QDAModel is : ' , y_test[:5])
print("="*10)
# ----------------------------------------------------
# x_axis = np.arange(0-0.1, 1+0.1, 0.001)
# xx0, xx1 = np.meshgrid(x_axis,x_axis)
# xxx = np.concatenate((np.ones((xx0.shape[0]*xx0.shape[1],2)),np.c_[xx0.ravel(), xx1.ravel()]),axis=1)
# Z = QDAModel.predict(xxx).reshape(xx0.shape)

# plt.figure("iris")
# sns.scatterplot(x=X[:,0], y=X[:,1], hue=y_hue, alpha=1, palette=['r','b','k']);
# # plt.contourf(xx0, xx1, Z, alpha=0.2, cmap=plt.cm.Paired)
# plt.show(block=True) 

# plt.figure("iris")
# sns.scatterplot(x=X_train[:,0], y=X_train[:,1], hue=y_hue, alpha=1, palette=['r','b','k']);
# plt.show(block=True) 
# plt.figure("iris")
# sns.scatterplot(x=X_test[:,0], y=X_test[:,1], hue=y_hue, alpha=1, palette=['r','b','k']);
# plt.show(block=True) 